---
title: "Investigate washout"
output: 
  pdf_document:
    latex_engine: xelatex

---

Some studies have washout, which can mean different things for different studies.


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(grid)
library(meta)
source("read-data.R")
df <- read.data()
```

These are all the studies that are labeled as having washout:


```{r}
kable(df %>% filter(WashOut == 'Y') %>% 
  select(JournalVolumePage, Author, Year, subtype, TypesofMIGSifany))
```

This study has pre- and post-washout and no measurements without washout. This is
equivalent to setting the pre and post op meds to 0:

```{r}
kable(df %>% filter(Washoutbaseline == PreOpIOPMean, !is.na(WashoutIOP)) %>% 
  select(JournalVolumePage, Author, Year, TypesofMIGSifany))
```

This study has preop washout and no washout in the post period. Virgin patients
were enrolled, and had 0 pre-op meds; only after were they put on meds:

```{r}
kable(df %>% filter(Washoutbaseline == PreOpIOPMean, is.na(WashoutIOP)) %>% 
  select(JournalVolumePage, Author, Year, TypesofMIGSifany))
```

These studies had both washout and regular measurements in the pre-period. That 
tells us about the relationship between meds and IOP:

```{r}
kable(df %>% filter(Washoutbaseline != PreOpIOPMean) %>% 
  mutate(mm.Hg.per.med = (Washoutbaseline - PreOpIOPMean)/RxPreOpMean,
         rel.p = 100*(1-(Washoutbaseline - PreOpIOPMean)/Washoutbaseline),
         rel.p.drop.per.med = 
           100*(1-exp(log(rel.p / 100) / RxPreOpMean))) %>%
  select(Author, Year, PreOpIOPMean, RxPreOpMean, mm.Hg.per.med, 
         rel.p, rel.p.drop.per.med), digits = 2)
```

Most commonly, 1 med corresponds to about a 15-20% drop in IOP; or a 4-5 mmHg 
drop. 

*Note*: Pfeiffer has washout in the pre-periods and the post-periods. It also 
has a baseline measurement (with meds).

This study has washout only in the last period; we can also use this to estimate
the drop in IOP per med:

```{r}
kable(df %>% filter(regexpr("Fea", Author)==TRUE) %>% 
  mutate(mm.Hg.per.med = (WashoutIOP - LastPeriodIOPMean)/RxPostOpMean,
         rel.p = 100*(1-(WashoutIOP - LastPeriodIOPMean)/WashoutIOP),
         rel.p.drop.per.med = 100*(1-exp(log(rel.p / 100) / RxPostOpMean))) %>%
  select(Author, Year, LastPeriodIOPMean, RxPostOpMean, mm.Hg.per.med, 
         rel.p, rel.p.drop.per.med), digits = 2)
```

This study is also in line with the estimate of 4-5mmHg, 15-20% drop in IOP per 
med.

# Study classifications

I went back and classified the studies depending on the washout type:

```{r}
kable(df %>% filter(washout.type != 'None') %>% 
  select(JournalVolumePage, Author, Year, subtype, TypesofMIGSifany, washout.type))
```

# Net effect - including IOP and meds

Let's see what happens when we add the IOP drop effect to the Rx drop effects.
We try different values of the translation value between meds and mmHg drop:
0, 2, 3, 4, or 5 mm Hg per Rx.

## Last period

```{r fig.width=10, fig.height=10, dev="cairo_pdf"}
mmhg.per.meds <- c(3.8)
for(mmhg.per.med in mmhg.per.meds) {
  
  df_ <- df %>% 
    filter(!is.na(RxChangeMean), 
           df$subtype != "AACG", 
           MIGsYorN == 'N',
           !is.na(LastPeriodAbsIOPChangeStdDev),
           !is.na(RxChangeStdDev)) %>% 
    mutate(subtype=factor(subtype),
           net.effect=LastPeriodAbsIOPChangeMean + 
             mmhg.per.med * RxChangeMean * (washout.type %in% c('None', 'Partial')) +
             mmhg.per.med * RxPostOpMean * (washout.type %in% c('Pre')),
           net.sem=sqrt(LastPeriodAbsIOPChangeStdDev ** 2 + 
             (mmhg.per.med * (washout.type %in% c('None', 'Partial', 'Pre')) * RxChangeStdDev) ** 2) / sqrt(LastPeriodEyes))
  m <- metagen(net.effect,
               net.sem, 
               study.name, 
               data=df_,
               byvar=subtype,
               n.e=LastPeriodEyes)
  forest(m, 
         comb.fixed=FALSE, 
         digits=1, 
         digits.se = 2, 
         overall=FALSE, 
         leftcols=c("studlab", "TE", "seTE", "n.e"),
         leftlabs=c("Study", "ΔIOP", "SE", "eyes"),
         refline=0)
  grid.text(
    paste0("Simulated net change in IOP in last period, ", mmhg.per.med, " mm Hg per med"), .5, .97, gp=gpar(cex=1.3))
  grid.lines(c(1, 1)*.5952, c(.11, .86), gp = gpar(lty=3))
  print(" ")
}
```

```{r fig.width=10, fig.height=6, dev="cairo_pdf"}
mmhg.per.meds <- c(3.8)
for(mmhg.per.med in mmhg.per.meds) {
  
  df_ <- df %>% 
    filter(!is.na(RxChangeMean), 
           df$subtype == "OAG", 
           MIGsYorN == 'N',
           !is.na(LastPeriodAbsIOPChangeStdDev),
           !is.na(RxChangeStdDev)) %>% 
    mutate(subtype=factor(subtype),
           net.effect=LastPeriodAbsIOPChangeMean + 
             mmhg.per.med * RxChangeMean * (washout.type %in% c('None', 'Partial')) +
             mmhg.per.med * RxPostOpMean * (washout.type %in% c('Pre')),
           net.sem=sqrt(LastPeriodAbsIOPChangeStdDev ** 2 + 
             (mmhg.per.med * (washout.type %in% c('None', 'Partial', 'Pre')) * RxChangeStdDev) ** 2) / sqrt(LastPeriodEyes))
  m <- metagen(net.effect,
               net.sem, 
               study.name, 
               data=df_,
               n.e=LastPeriodEyes,
                byvar=subtype
              )
  forest(m, 
         comb.fixed=FALSE, 
         digits=1, 
         digits.se = 2, 
         overall=FALSE, 
         leftcols=c("studlab", "TE", "seTE", "n.e"),
         leftlabs=c("Study", "ΔIOP", "SE", "eyes"))
  grid.text(
    paste0("Simulated net change in IOP in last period, ", mmhg.per.med, " mm Hg per med"), .5, .97, gp=gpar(cex=1.3))
  
  # Stupid hack to get a reference line at -2: set ref=-2 in forest, and mess with the number
  # until the two lines overlap.
  # TODO(Patrick): Banish this hack to the fiery pits of hell.
  grid.lines(c(1, 1)*.5807, c(.23, .75), gp = gpar(lty=3))
  print(" ")
}
```


# Conclusion

If you take into account the drop in number of meds in each study, you get an 
additional ~1mmHg drop in the OAG group. That's a net effect around 4 mmHg drop at
12 months and in the last period: quite a bit larger than the uncorrected
estimates we had previously.

There's another source of bias we can't correct for here: in some studies, less
potent medicines with better side effect profiles might have replaced more 
potent medicines in the post period, in response to better control of IOP after 
surgery. That would be measured as a net change of 0 between RxPreOp and 
RxPostOp, and it would result in an apparent increase in IOP, even though that's
a net positive for the patient. I'll leave it to the clinician to determine how
likely this is.